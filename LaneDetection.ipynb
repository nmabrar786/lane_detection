{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90db6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import matplotlib\n",
    "#import matplotlib.pyplot as plt\n",
    "#import argparse\n",
    "import cv2\n",
    "import imutils\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# identify filename of video to be analyzed\n",
    "cap = cv2.VideoCapture('testvideo2.mp4')\n",
    "\n",
    "# loop through until entire video file is played\n",
    "while(cap.isOpened()):\n",
    "\n",
    "    # read video frame & show on screen\n",
    "    ret, frame = cap.read()\n",
    "    # cv2.imshow(\"Original Scene\", frame)\n",
    "\n",
    "    # snip section of video frame of interest & show on screen\n",
    "    snip = frame[500:700,300:900]\n",
    "    cv2.imshow(\"Snip\",snip)\n",
    "\n",
    "    # create polygon (trapezoid) mask to select region of interest\n",
    "    mask = np.zeros((snip.shape[0], snip.shape[1]), dtype=\"uint8\")\n",
    "    pts = np.array([[25, 190], [275, 50], [380, 50], [575, 190]], dtype=np.int32)\n",
    "    cv2.fillConvexPoly(mask, pts, 255)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "\n",
    "    # apply mask and show masked image on screen\n",
    "    masked = cv2.bitwise_and(snip, snip, mask=mask)\n",
    "    cv2.imshow(\"Region of Interest\", masked)\n",
    "\n",
    "    # convert to grayscale then black/white to binary image\n",
    "    frame = cv2.cvtColor(masked, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = 200\n",
    "    frame = cv2.threshold(frame, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    cv2.imshow(\"Black/White\", frame)\n",
    "\n",
    "    # blur image to help with edge detection\n",
    "    blurred = cv2.GaussianBlur(frame, (11, 11), 0)\n",
    "    # cv2.imshow(\"Blurred\", blurred)\n",
    "\n",
    "    # identify edges & show on screen\n",
    "    edged = cv2.Canny(blurred, 30, 150)\n",
    "    cv2.imshow(\"Edged\", edged)\n",
    "\n",
    "    # perform full Hough Transform to identify lane lines\n",
    "    lines = cv2.HoughLines(edged, 1, np.pi / 180, 25)\n",
    "\n",
    "    # define arrays for left and right lanes\n",
    "    rho_left = []\n",
    "    theta_left = []\n",
    "    rho_right = []\n",
    "    theta_right = []\n",
    "\n",
    "    # ensure cv2.HoughLines found at least one line\n",
    "    if lines is not None:\n",
    "\n",
    "        # loop through all of the lines found by cv2.HoughLines\n",
    "        for i in range(0, len(lines)):\n",
    "\n",
    "            # evaluate each row of cv2.HoughLines output 'lines'\n",
    "            for rho, theta in lines[i]:\n",
    "\n",
    "                # collect left lanes\n",
    "                if theta < np.pi/2 and theta > np.pi/4:\n",
    "                    rho_left.append(rho)\n",
    "                    theta_left.append(theta)\n",
    "\n",
    "\n",
    "                # collect right lanes\n",
    "                if theta > np.pi/2 and theta < 3*np.pi/4:\n",
    "                    rho_right.append(rho)\n",
    "                    theta_right.append(theta)\n",
    "\n",
    "                   \n",
    "\n",
    "    # statistics to identify median lane dimensions\n",
    "    left_rho = np.median(rho_left)\n",
    "    left_theta = np.median(theta_left)\n",
    "    right_rho = np.median(rho_right)\n",
    "    right_theta = np.median(theta_right)\n",
    "\n",
    "    # plot median lane on top of scene snip\n",
    "    if left_theta > np.pi/4:\n",
    "        a = np.cos(left_theta); b = np.sin(left_theta)\n",
    "        x0 = a * left_rho; y0 = b * left_rho\n",
    "        offset1 = 250; offset2 = 800\n",
    "        x1 = int(x0 - offset1 * (-b)); y1 = int(y0 - offset1 * (a))\n",
    "        x2 = int(x0 + offset2 * (-b)); y2 = int(y0 + offset2 * (a))\n",
    "\n",
    "        cv2.line(snip, (x1, y1), (x2, y2), (0, 255, 0), 6)\n",
    "\n",
    "    if right_theta > np.pi/4:\n",
    "        a = np.cos(right_theta); b = np.sin(right_theta)\n",
    "        x0 = a * right_rho; y0 = b * right_rho\n",
    "        offset1 = 290; offset2 = 800\n",
    "        x3 = int(x0 - offset1 * (-b)); y3 = int(y0 - offset1 * (a))\n",
    "        x4 = int(x0 - offset2 * (-b)); y4 = int(y0 - offset2 * (a))\n",
    "\n",
    "        cv2.line(snip, (x3, y3), (x4, y4), (255, 0, 0), 6)\n",
    "\n",
    "\n",
    "\n",
    "    # overlay semi-transparent lane outline on original\n",
    "    if left_theta > np.pi/4 and right_theta > np.pi/4:\n",
    "        pts = np.array([[x1, y1], [x2, y2], [x3, y3], [x4, y4]], dtype=np.int32)\n",
    "\n",
    "        # (1) create a copy of the original:\n",
    "        overlay = snip.copy()\n",
    "        # (2) draw shapes:\n",
    "        cv2.fillConvexPoly(overlay, pts, (0, 255, 0))\n",
    "        # (3) blend with the original:\n",
    "        opacity = 0.4\n",
    "        cv2.addWeighted(overlay, opacity, snip, 1 - opacity, 0, snip)\n",
    "\n",
    "    cv2.imshow(\"Lined\", snip)\n",
    "\n",
    "\n",
    "   \n",
    "    # press the q key to break out of video\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# clear everything once finished\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72f3122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
